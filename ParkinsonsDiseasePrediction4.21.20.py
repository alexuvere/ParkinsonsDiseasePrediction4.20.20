# -*- coding: utf-8 -*-
"""AI in Health4.21.2020

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UEd6jS7-0wDA6L27votta_GtJoxejA4s
"""

#Description: This program dectects if an individual has Parkinson's Disease

# Get the dependencies 
import pandas as pd
import numpy as np 
from xgboost import XGBClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
import seaborn as sns

#Load the data set
from google.colab import files 
uploaded = files.upload()

#Load the data into a data frame
df = pd.read_csv('parkinsons.data')
df.head()

#Check data for missing values 
df.isnull().values.any()

#Get the number of rows and columns in the dataset
df.shape

#Get the target count
df['status'].value_counts()

percent_has_disease = 147 / (147 + 48) * 100
percent_dont_have_disease = 48 / (147 + 48) * 100
 
print('If I guess the individual did not have Parkinsons disease, I would be correct ' , percent_dont_have_disease, '% of the time' )
print('If I guess the individual has Parkinsons disease, I would be correct ' , percent_has_disease, '% of the time' )

# Visualize the count 
sns.countplot(df['status'])

#Get the Data type
df.dtypes

#Create the feature data set 
X = df.drop(['name'], 1)
X = np.array(X.drop(['status'], 1))
y = np.array(df['status'])

#Split the data into 80% training and 20% testing data sets 
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

#Transform the feature data to be values between 0 and 1
sc = MinMaxScaler(feature_range=(0,1))
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

# Create the xbgclassifier 
model = XGBClassifier().fit(x_train, y_train)

#get the models predictions 
predictions = model.predict(x_test)
predictions

y_test

#get the models accuracy, precision, recall and the f1- score
print(classification_report(y_test, predictions))